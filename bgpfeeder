#!/usr/bin/ruby
# Simple BGP talker implemented pretty much from RFC1771
#
# See http://src.bytemark.co.uk/trac/bgpfeeder for later versions and more
# information.
#
# (c) Bytemark Hosting 2009
#
require 'ipaddr'
require 'socket'
require 'logger'
require 'timeout'
require 'rubygems'
require 'ruby-debug'


class IPAddr
  MASK_REVERSE = {}
  (0..32).each { |b| MASK_REVERSE[4294967296 - (1<<b)] = 32-b }

  # BGP update messages contain IP prefixes encoded as <length,prefix>
  # tuples where length is 0-4 and prefix is the number of relevant
  # bytes of the IP address, e.g. 
  #    10.0.0.0/24 => [1,10]
  #    192.168.0.1/32 => [4,192,168,0,1]
  #    0.0.0.0/0 => [0]
  # 
  def bgp_encoded_prefix
    raise ArgumentError.new("Can't encode IPv6 for BGPv4") if ipv6?
    bits = MASK_REVERSE[@mask_addr]
    if bits > 24
      [bits, to_i].pack("cN")
    elsif bits > 16
      [bits, to_i].pack("cN")[0..3]
    elsif bits > 8
      [bits, to_i].pack("cN")[0..2]
    elsif bits > 0
      [bits, to_i].pack("cN")[0..1]
    else
      "\0" # i.e. 0.0.0.0/0
    end
  end

  def hash
    to_i | @mask_addr << 32 # good enough for IPv4
  end
end

module BGP
  REGEXP_IP_ADDRESS = /^\d+\.\d+\.\d+\.\d+$/
  REGEXP_IP_MASK    = /^\d+\.\d+\.\d+\.\d+\/(?:\d+|\d+\.\d+\.\d+\.\d+)$/

  Log = Logger.new(STDERR) # do we need any more than this?

  class NotificationException < Exception; end

  # Simple data structure for representing a BGP route update with
  # a single NEXT_HOP attribute.
  #
  # http://justrudd.org/2007/05/02/ruby-weirdness/ bit me when trying to do
  # array differences, so need to have hash & eql? implemented here and in
  # the IPAddr class (see above also).
  #
  class Update < Struct.new(:prefix, :next_hop, :withdraw)
    def initialize(prefix, next_hop=nil, withdraw=nil)
      prefix   = IPAddr.new(prefix) unless prefix.kind_of?(IPAddr)
      next_hop = IPAddr.new(next_hop) unless next_hop.kind_of?(IPAddr)
      withdraw = withdraw ? true : false
      super(prefix, next_hop, withdraw)
    end
    def withdraw?
      next_hop.nil? || withdraw
    end
    def new_route?
      next_hop && withdraw.nil?
    end
    def replace_route?
      next_hop && withdraw
    end
    def eql?(b)
      prefix == b.prefix && next_hop == b.next_hop && withdraw == b.withdraw
    end
    def hash
      (prefix.hash | next_hop.hash << 32) ^ (withdraw ? 0xffffffff : 0 )
    end
  end

  class Peer
    attr_reader :remote_host
    attr_reader :remote_port
    def peer_spec; "#{remote_host}:#{remote_port}"; end

    def initialize(database, peer_spec)
      @database = database
      @hold_time = database.hold_time # possibly overridden by remote OPEN

      @remote_host, @remote_port = peer_spec.split(":", 2)
      @remote_port = @remote_port.to_i
      @remote_port = 179 if @remote_port == 0

      @closed = false
    end

    def close
      @closed = true
    end

    def run
      while !@closed
        started = Time.now

        begin
          @s = TCPSocket.new(@remote_host, @remote_port)
        rescue Errno::ECONNREFUSED, Errno::ETIMEDOUT => e
          l_warn("failed BGPv4 connection due to #{e}, will try again in 60s")
          sleep 60
          break if @closed
          retry
        end

        begin
          do_open
          do_maintain_connection
        rescue NotificationException => ex
        end
        @s.close

        if !@closed
          retry_delay = 20 - (Time.now - started)
          retry_delay = 0 if retry_delay < 1
          l_warn("died, retrying "+
            (retry_delay == 0 ? "immediately" : "in #{retry_delay}s")
          )
          sleep retry_delay
        end
      end
    end

    protected

    def l_debug(msg); Log.debug("peer #{@remote_host}: #{msg}"); end
    def l_error(msg); Log.error("peer #{@remote_host}: #{msg}"); end
    def l_warn(msg); Log.warn("peer #{@remote_host}: #{msg}"); end
    def l_info(msg); Log.info("peer #{@remote_host}: #{msg}"); end

    TYPE_OPEN = 1
    TYPE_UPDATE = 2
    TYPE_NOTIFICATION = 3
    TYPE_KEEPALIVE = 4

    ERROR_EXPLANATIONS = [
      nil,
      "Message header error",
      "OPEN message error",
      "UPDATE message error", 
      "Hold timer expired",
      "State machine error",
      "Cease"
    ]

    # first communication once socket is open, send OPEN, expect to 
    # receive the same from peer, note its hold time.
    #
    def do_open
      send_open
      type, message = read_next_message
      if type == TYPE_NOTIFICATION
        handle_notification(message)
      else
        send_notification(1,1,"Expected OPEN, got #{type} instead") if type != TYPE_OPEN
        send_notification(2,1,"Unsupported BGP version, peer is speaking v#{message[0]}") if message[0] != 4
        peer_hold_time = message[3..4].unpack("n")[0]
        @hold_time = peer_hold_time if peer_hold_time < @database.hold_time
        l_debug "hold time for connection is #{@hold_time}s, sending first KEEPALIVE"
        send_keepalive
      end
    end

    # Simple polling loop to check for updates and respond to incoming
    # messages appropriately.  Can probably fix this to use IO.select
    # but maybe not necessary.
    #
    def do_maintain_connection
      warned_of_received_updates = false
      last_database_update = nil

      while !@closed
        # 1: send keepalive if it's due
        next_keepalive_at = @alive_last_sent + (@hold_time/3)
        send_keepalive if next_keepalive_at <= Time.now

        # 2: send updates if they're available (first call should give us
        # all entries)
        updates = @database.updates_since(last_database_update)
        if updates.length > 0
          send_updates(updates) 
          last_database_update = Time.now
        end

        # 3: handle incoming messages, waiting maximum 1s
        type, message = read_next_message(1)

        case type
          when TYPE_OPEN
            send_notification(5,0,"Received second OPEN message")

          when TYPE_UPDATE
            if !warned_of_received_updates
              l_warn("ignoring #{message.length} byte UPDATE from peer (further UPDATES will not be warned about, fix peer configuration!)")
              warned_of_received_updates = true
            end

          when TYPE_NOTIFICATION
            handle_notification(message)

          when TYPE_KEEPALIVE
            # @alive_last_seen set automatically by read_next_message

          when nil
            # timeout, nothing received, go round again

          else
            send_notification(1,3,"Unknown message type #{type} received")
        end

        # 4: notify and terminate connection if hold timer has expired
        send_notification(4,0,"Hold timer expired") if 
          Time.now - @alive_last_seen > @hold_time
      end

      send_notification(6,0,"User closed connection, peer will finish",false)
    end
    
    def handle_notification(message)
      code, subcode, data = message[0], message[1], message[2..7]
      l_error("received notification #{explain_error(code, subcode)}, disconnecting")
    end

    def explain_error(code, subcode)
      expl = ERROR_EXPLANATIONS[code]
      expl = "unknown" unless expl
      "#{code}.#{subcode} (#{expl})"
    end

    def send_open
      l_debug "sending OPEN for AS#{@database.autonomous_system} with hold time #{@database.hold_time} and BGP ID #{@database.bgp_identifier.to_s}"
      send_message(TYPE_OPEN, [
        4, # version, BGP 4
        @database.autonomous_system,
        @database.hold_time,
        @database.bgp_identifier.to_i,
        0 # optional parameters length
      ].pack("cnnNc"))
    end

    ATTR_ORIGIN = 1
    ATTR_AS_PATH = 2
    ATTR_NEXT_HOP = 3
    ATTR_LOCAL_PREF = 5

    ATYPE_OPTIONAL = 128
    ATYPE_TRANSITIVE = 64
    ATYPE_PARTIAL = 32
    ATYPE_EXTENDED_LENGTH = 16

    def send_updates(updates)
      # There is scope to aggregate updates a little bit here, but probably
      # would only clutter the code; as long as caller has ensured that
      # "replaced" routes are sent as one update, we avoid flaps which are
      # the main hazard.
      # 

      l_debug "send_updates: #{updates.inspect}"

      updates.each do |update|
        update_data = ""

        # 1: withdrawn routes, either 0 or 1 in this implementation
        #
        withdrawn_raw = update.withdraw? ? 
          update.prefix.bgp_encoded_prefix :
          ""
        update_data += [withdrawn_raw.length].pack("n") + withdrawn_raw

        # l_debug "withdrawn data: #{withdrawn_raw.inspect}"

        # 2: path attributes
        #
        # see 4.3, Path Attributes for encoding details, but we only
        # support next hop which is mandatory, transitive, complete  
        # and non-extended.  The attribute length is always 4, the length
        # of an IPv4 address, and the value is the normal 4-byte IPv4
        # encoding.
        #

        path_attributes_raw = 
          [ATYPE_TRANSITIVE, ATTR_ORIGIN, 1, 0].pack("cccc")+
#          [ATYPE_TRANSITIVE, ATTR_AS_PATH, 4, 1, 1, 65534].pack("cccccn")+
          [ATYPE_TRANSITIVE, ATTR_AS_PATH, 2, 1, 0].pack("ccccc")+
          [ATYPE_TRANSITIVE, ATTR_NEXT_HOP, 4, update.next_hop.to_i].pack("cccN")+
          [ATYPE_TRANSITIVE, ATTR_LOCAL_PREF, 4, 100].pack("cccN")
 
        update_data += [path_attributes_raw.length].pack("n") + path_attributes_raw

        # l_debug "path attributes data: #{path_attributes_raw.inspect}"

        # 3: prefixes that the above path attributes apply to, always 1
        # per update
        #
        update_data += update.prefix.bgp_encoded_prefix

        # l_debug "prefix data: #{update.prefix.bgp_encoded_prefix.inspect}"

        # send the complete message
        send_message(TYPE_UPDATE, update_data)
      end
    end

    def send_keepalive
      # l_debug { "sending KEEPALIVE" }
      send_message(TYPE_KEEPALIVE)
      @alive_last_sent = Time.now
    end

    # Notifications are always fatal
    def send_notification(code, subcode, explanation=nil, is_error=true)
      if is_error
        l_error(explanation) if explanation
        l_error("sending notification #{explain_error(code,subcode)}")
      else
        l_warn(explanation) if explanation
        l_warn("sending notification #{explain_error(code,subcode)}")
      end
      send_message(TYPE_NOTIFICATION,
        [code, subcode].pack("cc") + "\0\0\0\0\0\0"
      )
      raise NotificationException.new(explanation)
    end

    # Read next BGPv4 message, checking the marker and updating
    # @alive_last_seen so we know not to panic.
    #
    def read_next_message(timeout_seconds=0)
      begin
        timeout(timeout_seconds) do
          header = @s.read(19)
          return nil unless header
          # l_debug { "received header: "+header.inspect }
          send_notification(1,1,"Marker not detected (or out of sync)") if header[0..15] != MARKER
          length, type = header[16..18].unpack("nc")
          if type == TYPE_OPEN || type == TYPE_UPDATE || type == TYPE_KEEPALIVE
            @alive_last_seen = Time.now
          end
          data = @s.read(length-19)
          # l_debug { "received data: "+data.inspect }
          return [type, data]
        end
      rescue Timeout::Error => timeout
        # l_debug "timeout!"
      end
      nil
    end

    # Send BGPv4 message, adding appropriate header (19 is the length of the
    # marker plus message header which needs to be included)
    def send_message(type, message="")
      data = MARKER + [19 + message.length, type].pack("nc") + message
      # l_debug { "sent: "+data.inspect }
      @s.write(data)
    end

    def next_keepalive_at
      ideal_time = @hold_time / 3
      ideal_time = 1 if ideal_time == 0
      @alive_last_sent + ideal_time
    end

    MARKER = "\377"*16

  end

  # Utility class to watch a file, let us know when it has been updated, and
  # provide a quick way to read it into memory.
  # 
  class FileWatcher
    attr_reader :last_updated

    def initialize(file)
      raise Errno::ENOENT unless File.exists?(file)
      @file = file
      @last_updated = nil
    end

    def updated?
      updated_at = File.stat(@file).mtime
      if updated_at != @last_updated
        @last_updated = updated_at
        true
      else
        false
      end
    end

    def read_lines
      File.open(@file) do |fh|
        fh.read.split("\n")
      end
    end
  end

  class Database
    attr_reader :autonomous_system
    attr_reader :hold_time
    attr_reader :bgp_identifier

    def initialize(autonomous_system, bgp_identifier, hold_time, file)
      @autonomous_system = autonomous_system
      @bgp_identifier = IPAddr.new(bgp_identifier)
      @hold_time = hold_time
      @file = FileWatcher.new(file)
      @routes = []
      @route_updates = []
    end

    def updates_since(requested_time)
      poll_for_updates
      return @routes if requested_time.nil?

      # inefficient but clear!
      @route_updates.inject([]) do |list, (time_of_update, update)|
        if time_of_update < requested_time
          list
        else
          list + update
        end
      end
    end

    protected

    def poll_for_updates
      return unless @file.updated?
      new_routes = full_update_from_lines(@file.read_lines)

      routes_to_add    = new_routes - @routes
      routes_to_delete = @routes - new_routes

      routes_to_change = []
      # try to combine adds & deletes into a single "change" update to avoid
      # causing a flap.  FIXME: maybe a smarter/indexed search would make
      # this faster, can't see it being necessary for our use though?
      #
      routes_to_delete.each do |route|
        routes_to_add.each do |route2|
          if route2.prefix == route.prefix && route2.next_hop != route.next_hop
            routes_to_add.delete(route2)
            routes_to_delete.delete(route)
            route2.withdraw = true
            routes_to_change << route2
          end
        end
      end

      Log.info "routes file updated at #{@file.last_updated}: "+
        "#{routes_to_add.length} added, "+
        "#{routes_to_delete.length} deleted, "+
        "#{routes_to_change.length} changed"

      routes_to_add.each { |route| Log.warn "adding route #{route}" }
      routes_to_delete.each { |route| Log.warn "deleting route #{route}" }
      routes_to_change.each { |route| Log.warn "changing route #{route}" }

      # rewrite since we've pulled this out of our current route table
      routes_to_delete.each do |route|
        route.withdraw = true
        route.next_hop = nil
      end

       # add this calculated set of route updates to our log
      @route_updates << [@file.last_updated, 
        routes_to_add +
        routes_to_delete +
        routes_to_change
      ]

      # finally overwrite the full route table with the newly-parsed one
      @routes = new_routes

      Log.warn "routes file is empty" if @routes.empty?

      nil
    end

    _IP = '\d+\.\d+\.\d+\.\d+'
    FORMAT_LINUX = /^(#{_IP}\/\d+) (?:via )(#{_IP})/
    FORMAT_CISCO = /^(?:ip route )(#{_IP}) (#{_IP}) (#{_IP})$/

    # Parse a list of lines into a list of BGP::Update objects, silently
    # ignoring any errors
    #
    def full_update_from_lines(lines)
      lines.map do |line|
        case line
          when FORMAT_LINUX then Update.new($1,$2)
          when FORMAT_CISCO then Update.new("#{$1}/#{$2}", $3)
          else
            nil
        end
      end.compact
    end
  end

  class PeerManager
    def initialize(file, database)
      @file = FileWatcher.new(file)
      @database = database
      @peer_threads = {}
    end

    def run
      loop do
        if @file.updated?

          # Work out which peers have been added, and which removed
          #
          peer_list_new = @file.read_lines.
            select { |l| /^[\d+\.\:]+$/.match(l) }
          peer_list_finished = @peer_threads.keys - peer_list_new
          peer_list_to_start = peer_list_new - @peer_threads.keys

          # Kill off the peers we've finished with
          #
          peer_list_finished.each do |peer_spec|
            Log.info "closing peer #{peer_spec}"
            @peer_threads[peer_spec][:peer].close
          end

          # Initialise new ones 
          #
          peer_list_to_start.each do |peer_spec|
            Log.info "starting new peer #{peer_spec}"
            peer = Peer.new(@database, peer_spec)
            @peer_threads[peer_spec] = Thread.new { peer.run }
            @peer_threads[peer_spec][:peer] = peer
          end

          Log.warn("peers file is empty, nothing to do for now") if 
            peer_list_new.length == 0
        end

        sleep 1

        # Reap any that have finished
        #
        @peer_threads.each do |peer_spec, thread|
          next if thread.alive?
          begin
            thread.join
            Log.info "peer thread #{peer_spec} finished normally"
            @peer_threads.delete(peer_spec)
          rescue Exception => ex
            Log.error "peer thread #{peer_spec} finished with an exception: #{ex}"
            Log.error ex.backtrace.join("\n")+"\n"
          end
        end
      end
    end
  end 
end

if __FILE__ == $0
  include BGP
  if ARGV.length < 5
    STDERR.print "Syntax: #{$0} <AS number> <BGP identifier (IP)> <hold time> <routes file> <peers file>\n"
    exit 1
  end
  if ENV['BGPFEEDER_LOG_LEVEL']
    Log.level = Logger.const_get(ENV['BGPFEEDER_LOG_LEVEL'])
  else
    Log.level = Logger::INFO
  end
  db = Database.new(ARGV[0].to_i, ARGV[1], ARGV[2].to_i, ARGV[3])
  peers = PeerManager.new(ARGV[4], db)
  peers.run
end
